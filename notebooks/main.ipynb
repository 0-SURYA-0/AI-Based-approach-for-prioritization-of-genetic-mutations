{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from Bio import SeqIO\n",
    "from Bio.Seq import Seq\n",
    "from Bio.Align import substitution_matrices\n",
    "from Bio.Align import substitution_matrices\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Flatten, Conv1D\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Data Files\n",
    "from blosum62 import BLOSUM62_MATRIX\n",
    "from grantham_distance import GRANTHAM_DISTANCE_MATRIX\n",
    "\n",
    "print(\"All libraries and data files are successfully imported!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: A function to read and extract sequences from a .fna file\n",
    "def read_fna(file_path):\n",
    "    sequence = ''\n",
    "    with open(file_path, 'r') as file:\n",
    "        next(file) \n",
    "        for line in file:\n",
    "            line = line.strip()\n",
    "            if line: \n",
    "                sequence += line\n",
    "    return sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: A functions to calculate the BLOSUM62 score and Grantham distance between sequences\n",
    "blosum62 = substitution_matrices.load(\"BLOSUM62\")\n",
    "\n",
    "def calculate_blosum62(sequence, reference_sequence):\n",
    "    score = 0\n",
    "    \n",
    "    for aa1, aa2 in zip(sequence, reference_sequence):\n",
    "        score += blosum62.get((aa1, aa2), 0)\n",
    "    return score\n",
    "\n",
    "def calculate_grantham_distance(original_seq, mutated_seq):\n",
    "    distance = 0\n",
    "    for o, m in zip(original_seq, mutated_seq):\n",
    "        if o in GRANTHAM_DISTANCE_MATRIX and m in GRANTHAM_DISTANCE_MATRIX[o]:\n",
    "            distance += GRANTHAM_DISTANCE_MATRIX[o][m]\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: A function to extract features from original and mutated sequences\n",
    "def extract_features(original_seq, mutated_seq):\n",
    "    features = {\n",
    "        'original_sequence': original_seq,\n",
    "        'BLOSUM62': calculate_blosum62(original_seq, mutated_seq),\n",
    "        'Grantham Distance': calculate_grantham_distance(original_seq, mutated_seq)\n",
    "    }\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: A function to calculate the final weight based on feature contributions\n",
    "def calculate_final_weight(features):\n",
    "    weights = {\n",
    "        'BLOSUM62': 0.3,\n",
    "        'Grantham Distance': 0.2,\n",
    "        'Biochemical Change': 0.15,\n",
    "        'Conservation': 0.1,\n",
    "        'Structural Importance': 0.15,\n",
    "        'Pathogenicity': 0.1\n",
    "    }\n",
    "    final_weight = sum(weights[key] * features.get(key, 0) for key in weights)\n",
    "    return final_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: A function to calculate the mutation score based on feature weights\n",
    "def calculate_mutation_score(features):\n",
    "    weights = {\n",
    "        'BLOSUM62': 0.3,                 \n",
    "        'Grantham Distance': 0.2,        \n",
    "        'Biochemical Change': 0.15,     \n",
    "        'Conservation': 0.1,             \n",
    "        'Structural Importance': 0.15,   \n",
    "        'Pathogenicity': 0.1\n",
    "    }\n",
    "    final_score = sum(weights[key] * features.get(key, 0) for key in weights)\n",
    "    return final_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: A function to calculate the pathogenicity score based on multiple weighted factors\n",
    "def calculate_pathogenicity(benign_pathogenic, conservation_score, structural_importance, mutation_percentage):\n",
    "    weights = {\n",
    "        'benign_pathogenic': 0.4,  \n",
    "        'conservation_score': 0.2,  \n",
    "        'structural_importance': 0.2,  \n",
    "        'mutation_percentage': 0.2  \n",
    "    }\n",
    "\n",
    "    mutation_percentage_normalized = 100 - mutation_percentage  \n",
    "\n",
    "    pathogenicity_score = (\n",
    "        weights['benign_pathogenic'] * benign_pathogenic +\n",
    "        weights['conservation_score'] * conservation_score +\n",
    "        weights['structural_importance'] * structural_importance +\n",
    "        weights['mutation_percentage'] * (mutation_percentage_normalized / 100)\n",
    "    )\n",
    "\n",
    "    return pathogenicity_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7: A function to map and extract features from mutated sequence files and calculate final weights\n",
    "def map_and_extract(original_seq, mutated_seq_files):\n",
    "    results = []\n",
    "    for mutated_file in mutated_seq_files:\n",
    "        mutated_seq = read_fna(mutated_file)\n",
    "        features = extract_features(original_seq, mutated_seq)\n",
    "        features['Final Weight'] = calculate_final_weight(features)\n",
    "        features['original_sequence'] = original_seq \n",
    "        results.append(features)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 8: A functions to read sequences, load data, prepare it for LSTM, and train the model\n",
    "def read_sequence_from_fna(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        next(file)  \n",
    "        sequence = ''.join(line.strip() for line in file)  \n",
    "    return sequence\n",
    "\n",
    "def load_data(file_paths):\n",
    "    X = []  # Features\n",
    "    y = []  # Labels\n",
    "    for file_path in file_paths:\n",
    "        sequence = read_sequence_from_fna(file_path)\n",
    "        X.append(sequence)\n",
    "        y.append(1 if 'mutated' in file_path else 0)  \n",
    "    return X, y\n",
    "\n",
    "def create_char_to_int_mapping():\n",
    "    chars = set('ACGT')\n",
    "    char_to_int = {char: idx for idx, char in enumerate(chars)}\n",
    "    return char_to_int\n",
    "\n",
    "def prepare_data_for_lstm(X, y, char_to_int):\n",
    "    int_data = []\n",
    "    for seq in X:\n",
    "        int_seq = [char_to_int.get(char, 0) for char in seq]  \n",
    "        int_data.append(int_seq)\n",
    "\n",
    "    print(\"Mapped int_data:\", int_data)\n",
    "\n",
    "    if not int_data or all(len(seq) == 0 for seq in int_data):\n",
    "        raise ValueError(\"All sequences are empty or contain only unmapped characters.\")\n",
    "\n",
    "    max_length = max(len(seq) for seq in int_data)\n",
    "    int_data = pad_sequences(int_data, maxlen=max_length, padding='post')\n",
    "\n",
    "    y = np.array(y)\n",
    "\n",
    "    return np.array(int_data), y\n",
    "\n",
    "def train_lstm(X, y):\n",
    "    X, y = prepare_data_for_lstm(X, y, create_char_to_int_mapping())\n",
    "    \n",
    "    print(\"Shape of X:\", X.shape)  \n",
    "\n",
    "    if len(X.shape) == 2: \n",
    "        X = np.expand_dims(X, axis=1)\n",
    "    elif len(X.shape) != 3:\n",
    "        raise ValueError(\"Input X must have shape (samples, timesteps, features)\")\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(50, input_shape=(X.shape[1], X.shape[2]))) \n",
    "    model.add(Dense(1, activation='sigmoid')) \n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    model.fit(X, y, epochs=10, batch_size=32, verbose=1)  \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def prepare_data_for_cnn(data):\n",
    "    sequences = [features['original_sequence'] for features in data]\n",
    "    sequences = [''.join(seq) for seq in sequences]\n",
    "\n",
    "    amino_acid_to_int = {aa: idx for idx, aa in enumerate(sorted(set(''.join(sequences))))}\n",
    "\n",
    "    int_data = [[amino_acid_to_int[aa] for aa in seq] for seq in sequences]\n",
    "    \n",
    "    max_length = max(len(seq) for seq in int_data)\n",
    "    padded_data = np.array([np.pad(seq, (0, max_length - len(seq)), 'constant') for seq in int_data])\n",
    "\n",
    "    X = padded_data.reshape(padded_data.shape[0], padded_data.shape[1], 1)  \n",
    "    \n",
    "    y = np.array([features.get('Target', 0) for features in data]) \n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_cnn(X_train, y_train):\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=32, kernel_size=3, activation='relu', input_shape=(X_train.shape[1], 1)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(50, activation='relu'))  \n",
    "    model.add(Dense(1))  \n",
    "    model.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])\n",
    "    model.fit(X_train, y_train, epochs=20, batch_size=64)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_scores_for_file(file_path, reference_sequence):\n",
    "    scores = {}\n",
    "    for record in SeqIO.parse(file_path, \"fasta\"):\n",
    "        sequence = record.seq\n",
    "        score = calculate_blosum62(sequence, reference_sequence)\n",
    "        scores[record.id] = score\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_directory(directory_path, reference_sequence):\n",
    "    all_scores = {}\n",
    "    for filename in os.listdir(directory_path):\n",
    "        if filename.endswith(\".fna\"):\n",
    "            file_path = os.path.join(directory_path, filename)\n",
    "            print(f\"Processing file: {file_path}\")\n",
    "            scores = calculate_scores_for_file(file_path, reference_sequence)\n",
    "            all_scores[filename] = scores\n",
    "    return all_scores\n",
    "\n",
    "reference_sequence = Seq(\"YOUR_REFERENCE_PROTEIN_SEQUENCE\")\n",
    "train_directory = \"BLOSUM62 SCORE FILE/Mutation_train_protein\"  \n",
    "test_directory = \"BLOSUM62 SCORE FILE/Mutation_test_protein\"    \n",
    "\n",
    "train_scores = process_directory(train_directory, reference_sequence)\n",
    "test_scores = process_directory(test_directory, reference_sequence)\n",
    "\n",
    "print(\"Training Dataset Scores:\")\n",
    "for file, scores in train_scores.items():\n",
    "    print(f\"{file}: {scores}\")\n",
    "\n",
    "print(\"\\nTesting Dataset Scores:\")\n",
    "for file, scores in test_scores.items():\n",
    "    print(f\"{file}: {scores}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prioritize_mutations(results):\n",
    "    return sorted(results, key=lambda x: x['Final Weight'], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_and_plot_mutations(original_seq, test_files):\n",
    "    results = []\n",
    "    for test_file in test_files:\n",
    "        mutated_seq = read_fna(test_file)\n",
    "        features = extract_features(original_seq, mutated_seq)\n",
    "        \n",
    "        if 'BLOSUM62' not in features or features['BLOSUM62'] == 0:\n",
    "            print(f\"Warning: BLOSUM62 score is missing or zero for {test_file}. Check feature extraction.\")\n",
    "        \n",
    "        if 'Pathogenicity' not in features:\n",
    "            features['Pathogenicity'] = 0  \n",
    "        \n",
    "        features['Final Score'] = calculate_mutation_score(features)\n",
    "        features['Test File'] = test_file  \n",
    "        results.append(features)\n",
    "    \n",
    "    sorted_results = sorted(results, key=lambda x: x['Final Score'], reverse=True)\n",
    "    \n",
    "    most_pathogenic_mutation = sorted_results[0]\n",
    "    \n",
    "    # Plotting\n",
    "    mutation_names = [result['Test File'] for result in results]\n",
    "    scores = [result['Final Score'] for result in results]\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(x=mutation_names, y=scores)  \n",
    "    plt.xlabel(\"Mutation (Test File)\")\n",
    "    plt.ylabel(\"Pathogenic Score\")\n",
    "    plt.title(\"Most Prioritised Mutation (Based on Metrics)\")\n",
    "    plt.xticks(rotation=45, ha=\"right\")\n",
    "    \n",
    "    \n",
    "    max_score_index = mutation_names.index(most_pathogenic_mutation['Test File'])\n",
    "    plt.bar(max_score_index, scores[max_score_index], color='red', label=\"Most Pathogenic\")\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"Most Pathogenic Mutation:\")\n",
    "    print(f\"File: {most_pathogenic_mutation['Test File']}\")\n",
    "    print(f\"Score: {most_pathogenic_mutation['Final Score']}\")\n",
    "    print(\"Reasons based on feature scores:\")\n",
    "    for feature, value in most_pathogenic_mutation.items():\n",
    "        if feature in ['BLOSUM62', 'Grantham Distance', 'Biochemical Change', 'Conservation', 'Structural Importance', 'Pathogenicity']:\n",
    "            print(f\"{feature}: {value}\")\n",
    "    \n",
    "    return most_pathogenic_mutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mutation_percentage(original_seq, mutated_seq):\n",
    "    matches = sum(1 for o, m in zip(original_seq, mutated_seq) if o == m)\n",
    "    return (len(mutated_seq) - matches) / len(mutated_seq) * 100\n",
    "\n",
    "def calculate_pathogenicity(benign_pathogenic, conservation_score, structural_importance, mutation_percentage):\n",
    "    weights = {\n",
    "        'benign_pathogenic': 0.4,\n",
    "        'conservation_score': 0.2,\n",
    "        'structural_importance': 0.2,\n",
    "        'mutation_percentage': 0.2\n",
    "    }\n",
    "\n",
    "    mutation_percentage_normalized = 100 - mutation_percentage\n",
    "    pathogenicity_score = (\n",
    "        weights['benign_pathogenic'] * benign_pathogenic +\n",
    "        weights['conservation_score'] * conservation_score +\n",
    "        weights['structural_importance'] * structural_importance +\n",
    "        weights['mutation_percentage'] * (mutation_percentage_normalized / 100)\n",
    "    )\n",
    "    return pathogenicity_score\n",
    "\n",
    "def process_mutated_files(original_file, mutated_files):\n",
    "    original_sequence = read_fna(original_file)\n",
    "    if not original_sequence:\n",
    "        print(\"Error: Original sequence could not be read.\")\n",
    "        return {}\n",
    "\n",
    "    results = {}\n",
    "    for mutated_file in mutated_files:\n",
    "        mutated_sequence = read_fna(mutated_file)\n",
    "        if not mutated_sequence:\n",
    "            print(f\"Error: Mutated sequence in {mutated_file} could not be read.\")\n",
    "            continue\n",
    "        \n",
    "        benign_pathogenic = 1  \n",
    "        conservation_score = 0.9  \n",
    "        structural_importance = 0.8 \n",
    "        \n",
    "        mutation_percentage = calculate_mutation_percentage(original_sequence, mutated_sequence)\n",
    "        pathogenicity_score = calculate_pathogenicity(benign_pathogenic, conservation_score, structural_importance, mutation_percentage)\n",
    "        results[mutated_file] = pathogenicity_score\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_results(results):\n",
    "    mutated_files = list(results.keys())\n",
    "    pathogenicity_scores = list(results.values())\n",
    "\n",
    "    plt.bar(mutated_files, pathogenicity_scores, color='red')\n",
    "    plt.xlabel(\"Mutated Files\")\n",
    "    plt.ylabel(\"Pathogenicity Score\")\n",
    "    plt.title(\"Pathogenicity Scores of Different Mutations\")\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()  \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    original_file = 'gene_DNA_Assembly_GRCh38.fna'\n",
    "    original_seq = read_fna(original_file)\n",
    "    \n",
    "    mutated_files = [f\"Mutation_train/Mutation_train{i}.fna\" for i in range(1, 17)]\n",
    "    test_files = [\n",
    "        \"Mutation_test/Mutation_test1.fna\",\n",
    "        \"Mutation_test/Mutation_test2.fna\",\n",
    "        \"Mutation_test/Mutation_test3.fna\",\n",
    "        \"Mutation_test/Mutation_test4.fna\"\n",
    "    ]\n",
    "    \n",
    "    results = map_and_extract(original_seq, mutated_files)\n",
    "    \n",
    "    X_sequences = [features['original_sequence'] for features in results]\n",
    "    y_labels = [features.get('Target', 0) for features in results]\n",
    "    \n",
    "    char_to_int = create_char_to_int_mapping()\n",
    "    \n",
    "    X_lstm, y_lstm = prepare_data_for_lstm(X_sequences, y_labels, char_to_int)\n",
    "    X_train_lstm, X_test_lstm, y_train_lstm, y_test_lstm = train_test_split(X_lstm, y_lstm, test_size=0.2, random_state=7)\n",
    "    \n",
    "    lstm_model = train_lstm(X_train_lstm, y_train_lstm)\n",
    "    \n",
    "    X_cnn, y_cnn = prepare_data_for_cnn(results)\n",
    "    X_train_cnn, X_test_cnn, y_train_cnn, y_test_cnn = train_test_split(X_cnn, y_cnn, test_size=0.2, random_state=7)\n",
    "    \n",
    "    cnn_model = train_cnn(X_train_cnn, y_train_cnn)\n",
    "    \n",
    "    prioritized_results = prioritize_mutations(results)\n",
    "    \n",
    "    print(\"Prioritized Mutations:\")\n",
    "    for result in prioritized_results:\n",
    "        print(result)\n",
    "    \n",
    "    \n",
    "    most_pathogenic_mutation = evaluate_and_plot_mutations(original_seq, test_files)\n",
    "    \n",
    "    mutated_files = [\n",
    "        r'Mutation_test\\Mutation_test1.fna',\n",
    "        r'Mutation_test\\Mutation_test2.fna',\n",
    "        r'Mutation_test\\Mutation_test3.fna',\n",
    "        r'Mutation_test\\Mutation_test4.fna'\n",
    "    ]\n",
    "    \n",
    "    results = process_mutated_files(original_file, mutated_files)\n",
    "    \n",
    "    print(\"Pathogenicity scores for test files:\")\n",
    "    for mutated_file, score in results.items():\n",
    "        print(f\"Pathogenicity score for {mutated_file}: {score:.4f}\")\n",
    "    \n",
    "    visualize_results(results)\n",
    "\n",
    "    if \"Mutation_test/Mutation_test4.fna\" in results:\n",
    "        print(f\"Pathogenicity score for Mutation_test\\\\Mutation_test4.fna: {results['Mutation_test/Mutation_test4.fna']:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
